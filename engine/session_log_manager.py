"""
ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
SessionLogManager - æ—¢å­˜SessionLoggerã¨ã®çµ±åˆã«ã‚ˆã‚‹è‡ªå‹•ãƒ­ã‚°ç”Ÿæˆ
"""

import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Dict, Any, List
from datetime import datetime
from enum import Enum

from .session_logging import SessionLogger, LogLevel, EventType

logger = logging.getLogger(__name__)


@dataclass
class LogResult:
    """ãƒ­ã‚°æ“ä½œã®çµæœã¨çŠ¶æ…‹æƒ…å ±"""
    success: bool
    log_path: Optional[Path]
    error_message: Optional[str]
    session_id: Optional[str]


@dataclass  
class DiagnosticReport:
    """ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­çµæœã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æƒ…å ±"""
    timestamp: datetime
    session_logger_enabled: bool
    log_directory_exists: bool
    permissions_valid: bool
    issues: List[str]
    recommendations: List[str]
    
    def has_issues(self) -> bool:
        """å•é¡ŒãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        return len(self.issues) > 0
    
    def format_report(self) -> str:
        """è¨ºæ–­æƒ…å ±ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤ºç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        report_lines = [
            f"ğŸ” ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ - {self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:",
            f"  â€¢ SessionLoggeræœ‰åŠ¹: {'âœ…' if self.session_logger_enabled else 'âŒ'}",
            f"  â€¢ ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {'âœ…' if self.log_directory_exists else 'âŒ'}",
            f"  â€¢ æ›¸ãè¾¼ã¿æ¨©é™: {'âœ…' if self.permissions_valid else 'âŒ'}",
            ""
        ]
        
        if self.issues:
            report_lines.extend([
                "âš ï¸  æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:",
                *[f"  â€¢ {issue}" for issue in self.issues],
                ""
            ])
        
        if self.recommendations:
            report_lines.extend([
                "ğŸ’¡ æ¨å¥¨äº‹é …:",
                *[f"  â€¢ {rec}" for rec in self.recommendations],
                ""
            ])
        
        if not self.has_issues():
            report_lines.append("âœ… ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã§ã™")
        
        return "\n".join(report_lines)


@dataclass
class LogFileInfo:
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨çµ±è¨ˆ"""
    file_path: Path
    student_id: str
    session_id: str
    created_at: datetime
    file_size: int
    entry_count: int
    last_modified: datetime


@dataclass
class LogConfig:
    """ãƒ­ã‚°è¨­å®šã¨ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚ªãƒ—ã‚·ãƒ§ãƒ³"""
    logging_level: str = 'INFO'
    max_file_size_mb: int = 10
    max_log_files: int = 100
    google_sheets_enabled: bool = False
    google_sheets_url: str = ''
    backup_enabled: bool = True
    auto_cleanup_enabled: bool = True


@dataclass
class ValidationResult:
    """ãƒ­ã‚°æ•´åˆæ€§æ¤œè¨¼çµæœ"""
    is_valid: bool
    total_entries: int
    valid_entries: int
    corrupted_entries: List[int]
    missing_fields: List[str]
    error_details: List[str]
    
    def get_recovery_suggestions(self) -> List[str]:
        """ä¿®å¾©æ¨å¥¨äº‹é …ã‚’è¿”å´"""
        suggestions = [
            "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
            "ç ´æã—ãŸã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œã§ãã¾ã™",
        ]
        
        if self.corrupted_entries:
            suggestions.append(f"ç ´æã—ãŸã‚¨ãƒ³ãƒˆãƒª: è¡Œ {', '.join(map(str, self.corrupted_entries))}")
            
        return suggestions


class LoggingSystemError(Exception):
    """ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ï¼ˆåŸºåº•ã‚¯ãƒ©ã‚¹ï¼‰"""
    pass


class LogFileAccessError(LoggingSystemError):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹/æ¨©é™ã‚¨ãƒ©ãƒ¼"""
    
    def __init__(self, message: str, file_path: Optional[Path] = None):
        super().__init__(message)
        self.file_path = file_path
    
    def suggest_recovery(self) -> List[str]:
        """å›å¾©æ–¹æ³•ã®ææ¡ˆ"""
        suggestions = [
            "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ (chmod 644)",
            "è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ›¸ãè¾¼ã¿æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
        ]
        
        if self.file_path:
            suggestions.append(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {self.file_path}")
            
        return suggestions


class LogValidationError(LoggingSystemError):
    """ãƒ­ã‚°æ¤œè¨¼/æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼"""
    
    def __init__(self, message: str, corrupted_entries: Optional[List[int]] = None):
        super().__init__(message)
        self.corrupted_entries = corrupted_entries or []
    
    def suggest_recovery(self) -> List[str]:
        """å›å¾©æ–¹æ³•ã®ææ¡ˆ"""
        suggestions = [
            "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
            "ç ´æã—ãŸã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œã§ãã¾ã™",
        ]
        
        if self.corrupted_entries:
            suggestions.append(f"ç ´æã—ãŸã‚¨ãƒ³ãƒˆãƒª: è¡Œ {', '.join(map(str, self.corrupted_entries))}")
            
        return suggestions


class ConfigurationError(LoggingSystemError):
    """è¨­å®š/ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼"""
    
    def __init__(self, message: str, config_key: Optional[str] = None):
        super().__init__(message)
        self.config_key = config_key
    
    def suggest_recovery(self) -> List[str]:
        """å›å¾©æ–¹æ³•ã®ææ¡ˆ"""
        suggestions = [
            "config.pyã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„",
            "ç’°å¢ƒå¤‰æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
            "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®å®Ÿè¡Œã‚’è©¦ã—ã¦ãã ã•ã„",
        ]
        
        if self.config_key:
            suggestions.append(f"å•é¡Œã®è¨­å®šé …ç›®: {self.config_key}")
            
        return suggestions

class SessionLogManager:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.session_logger: Optional[SessionLogger] = None
        self.log_file_path: Optional[Path] = None
        self.enabled = False
        # è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self._max_file_size = 10 * 1024 * 1024  # 10MB
        self._max_log_files = 100
        self._google_sheets_enabled = False
        
        logger.debug("SessionLogManageråˆæœŸåŒ–å®Œäº†")
    
    def diagnose_logging_system(self) -> DiagnosticReport:
        """ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚’å®Ÿè¡Œã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        issues = []
        recommendations = []
        
        # SessionLoggerã®çŠ¶æ…‹ç¢ºèª
        session_logger_enabled = self.session_logger is not None
        if not session_logger_enabled:
            issues.append("SessionLoggerãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            recommendations.append("enable_default_logging()ã‚’å‘¼ã³å‡ºã—ã¦ãã ã•ã„")
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
        log_directory_exists = self._check_log_directories()
        if not log_directory_exists:
            issues.append("ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            recommendations.append("data/sessionsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„")
        
        # æ›¸ãè¾¼ã¿æ¨©é™ã®ç¢ºèª
        permissions_valid = self._verify_permissions()
        if not permissions_valid:
            issues.append("ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®æ›¸ãè¾¼ã¿æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
            recommendations.append("ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¨©é™è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        return DiagnosticReport(
            timestamp=datetime.now(),
            session_logger_enabled=session_logger_enabled,
            log_directory_exists=log_directory_exists,
            permissions_valid=permissions_valid,
            issues=issues,
            recommendations=recommendations
        )
    
    def _check_log_directories(self) -> bool:
        """ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ã‚’ç¢ºèª"""
        try:
            # config.pyã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€
            import config
            data_dir = config.ROOT_DIR / "data"
            sessions_dir = data_dir / "sessions"
            
            # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            return sessions_dir.exists() and sessions_dir.is_dir()
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _check_session_logger_status(self) -> bool:
        """SessionLoggerã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        if not self.session_logger:
            return False
        
        # SessionLoggerãŒé©åˆ‡ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        return hasattr(self.session_logger, 'log_event')
    
    def _verify_permissions(self) -> bool:
        """æ›¸ãè¾¼ã¿æ¨©é™ã‚’ç¢ºèª"""
        try:
            import config
            sessions_dir = config.ROOT_DIR / "data" / "sessions"
            
            if not sessions_dir.exists():
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆã‚’è©¦è¡Œ
                sessions_dir.mkdir(parents=True, exist_ok=True)
            
            # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã‚’è©¦è¡Œ
            test_file = sessions_dir / ".permission_test"
            test_file.write_text("test")
            test_file.unlink()  # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            
            return True
        except Exception as e:
            logger.error(f"æ¨©é™ç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def enable_default_logging(self, student_id: str, stage_id: str, force_enable: bool = True) -> LogResult:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ­ã‚°æœ‰åŠ¹åŒ–ï¼ˆmain.pyå®Ÿè¡Œæ™‚ã®è‡ªå‹•ãƒ­ã‚°ç”Ÿæˆï¼‰"""
        try:
            if self.enabled and not force_enable:
                logger.debug("ãƒ­ã‚°æ©Ÿèƒ½ã¯æ—¢ã«æœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
                return LogResult(
                    success=True,
                    log_path=self.log_file_path,
                    error_message=None,
                    session_id=self.session_logger.session_id if self.session_logger else None
                )
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå­¦ç”ŸIDã®ä½¿ç”¨
            if not student_id or student_id == "":
                student_id = "DEFAULT_USER"
                logger.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå­¦ç”ŸIDã‚’ä½¿ç”¨ã—ã¾ã™: DEFAULT_USER")
            
            # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™
            self._ensure_log_directories()
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®åˆæœŸåŒ–
            import config
            base_log_dir = config.ROOT_DIR / "data" / "sessions"
            log_dir = base_log_dir / stage_id  # data/sessions/stage01/
            log_dir.mkdir(parents=True, exist_ok=True)
            
            # ç°¡æ˜“ç‰ˆãƒ­ã‚°å®Ÿè£…ï¼ˆSessionLoggerã®è¤‡é›‘æ€§ã‚’å›é¿ï¼‰
            from datetime import datetime
            import uuid
            import json
            
            generated_session_id = str(uuid.uuid4())[:8]
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            log_filename = f"{timestamp}_{student_id}.json"  # JSONå½¢å¼ã«å¤‰æ›´
            self.log_file_path = log_dir / log_filename
            
            # ç°¡æ˜“ç‰ˆã®SessionLoggerä»£æ›¿ã‚¯ãƒ©ã‚¹ä½œæˆ
            self._create_simple_logger(log_dir, generated_session_id, student_id)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¨­å®šï¼ˆattempt_countã¯é™¤å»ï¼‰
            self.session_logger.set_session_info(stage_id)
            
            self.enabled = True
            
            print(f"âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
            print(f"ğŸ“‚ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {self.log_file_path}")
            print(f"ğŸ‘¤ å­¦ç”ŸID: {student_id}")
            print(f"ğŸ¯ ã‚¹ãƒ†ãƒ¼ã‚¸: {stage_id}")
            
            logger.info(f"SessionLoggeråˆæœŸåŒ–å®Œäº†: {generated_session_id}")
            
            return LogResult(
                success=True,
                log_path=self.log_file_path,
                error_message=None,
                session_id=generated_session_id
            )
            
        except Exception as e:
            error_msg = f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®æœ‰åŠ¹åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
            logger.error(f"ãƒ­ã‚°æœ‰åŠ¹åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            
            return LogResult(
                success=False,
                log_path=None,
                error_message=error_msg,
                session_id=None
            )
    
    def _ensure_log_directories(self) -> None:
        """å¿…è¦ãªãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        try:
            import config
            directories = [
                config.ROOT_DIR / "data",
                config.ROOT_DIR / "data" / "sessions",
                config.ROOT_DIR / "data" / "diagnostics",
                config.ROOT_DIR / "data" / "exports",
                config.ROOT_DIR / "data" / "backup" / "archived"
            ]
            
            for dir_path in directories:
                dir_path.mkdir(parents=True, exist_ok=True)
                logger.debug(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ/ç¢ºèª: {dir_path}")
                
        except Exception as e:
            logger.error(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            raise LogFileAccessError(f"ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def show_log_info(self) -> List[LogFileInfo]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"""
        try:
            import config
            import json
            from os import stat
            
            log_files = []
            sessions_dir = config.ROOT_DIR / "data" / "sessions"
            
            if not sessions_dir.exists():
                print("ğŸ“‚ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                print(f"   ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {sessions_dir}")
                return []
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å«ã‚€.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æ¤œç´¢ï¼ˆæ–°å½¢å¼ï¼‰ã¨.jsonlãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ—§å½¢å¼ï¼‰ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
            json_files = list(sessions_dir.rglob("*.json"))
            jsonl_files = list(sessions_dir.rglob("*.jsonl"))
            all_files = json_files + jsonl_files
            
            if not all_files:
                print("ğŸ“‚ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                print(f"   ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {sessions_dir}")
                return []
            
            print(f"ğŸ“Š ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ± ({len(all_files)}ä»¶)")
            print("=" * 60)
            
            for file_path in sorted(all_files, key=lambda f: f.stat().st_mtime, reverse=True):
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    stat_info = file_path.stat()
                    file_size = stat_info.st_size
                    last_modified = datetime.fromtimestamp(stat_info.st_mtime)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å­¦ç”ŸIDã‚’æŠ½å‡º
                    student_id = self._extract_student_id_from_filename(file_path.name)
                    
                    # ã‚¨ãƒ³ãƒˆãƒªæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    entry_count = self._count_log_entries(file_path)
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’å–å¾—
                    session_id = self._extract_session_id_from_file(file_path)
                    
                    # ä½œæˆæ—¥æ™‚ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬ï¼‰
                    created_at = self._extract_created_at_from_filename(file_path.name) or last_modified
                    
                    log_info = LogFileInfo(
                        file_path=file_path,
                        student_id=student_id,
                        session_id=session_id,
                        created_at=created_at,
                        file_size=file_size,
                        entry_count=entry_count,
                        last_modified=last_modified
                    )
                    
                    log_files.append(log_info)
                    
                    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤º
                    print(f"ğŸ“ {file_path.name}")
                    print(f"   ğŸ‘¤ å­¦ç”ŸID: {student_id}")
                    print(f"   ğŸ†” ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_id}")
                    print(f"   ğŸ“… ä½œæˆ: {created_at.strftime('%Y-%m-%d %H:%M:%S')}")
                    print(f"   ğŸ“ ã‚µã‚¤ã‚º: {self._format_file_size(file_size)}")
                    print(f"   ğŸ“Š ã‚¨ãƒ³ãƒˆãƒªæ•°: {entry_count}")
                    print(f"   ğŸ”„ æ›´æ–°: {last_modified.strftime('%Y-%m-%d %H:%M:%S')}")
                    print()
                    
                except Exception as e:
                    logger.error(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
                    continue
            
            return log_files
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°æƒ…å ±è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ ãƒ­ã‚°æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return []
    
    def get_latest_log_path(self) -> Optional[Path]:
        """æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”å´ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¯¾å¿œï¼‰"""
        try:
            import config
            sessions_dir = config.ROOT_DIR / "data" / "sessions"
            
            if not sessions_dir.exists():
                return None
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å«ã‚€å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æ¤œç´¢
            json_files = list(sessions_dir.rglob("*.json"))
            jsonl_files = list(sessions_dir.rglob("*.jsonl"))
            all_files = json_files + jsonl_files
            
            if not all_files:
                return None
            
            # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆæ›´æ–°æ™‚åˆ»é †ï¼‰
            latest_file = max(all_files, key=lambda f: f.stat().st_mtime)
            
            print(f"ğŸ“‚ æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file}")
            print(f"   ğŸ”„ æ›´æ–°æ™‚åˆ»: {datetime.fromtimestamp(latest_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')}")
            
            return latest_file
            
        except Exception as e:
            logger.error(f"æœ€æ–°ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_student_id_from_filename(self, filename: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å­¦ç”ŸIDã‚’æŠ½å‡º"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åå½¢å¼: YYYYMMDD_HHMMSS_STUDENT_ID.json/.jsonl
            parts = filename.replace('.jsonl', '').replace('.json', '').split('_')
            if len(parts) >= 3:
                return parts[2]  # 3ç•ªç›®ã®éƒ¨åˆ†ãŒå­¦ç”ŸID
            return "UNKNOWN"
        except Exception:
            return "UNKNOWN"
    
    def _extract_created_at_from_filename(self, filename: str) -> Optional[datetime]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ä½œæˆæ—¥æ™‚ã‚’æŠ½å‡º"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åå½¢å¼: YYYYMMDD_HHMMSS_STUDENT_ID.json/.jsonl
            parts = filename.replace('.jsonl', '').replace('.json', '').split('_')
            if len(parts) >= 2:
                date_part = parts[0]  # YYYYMMDD
                time_part = parts[1]  # HHMMSS
                datetime_str = f"{date_part}_{time_part}"
                return datetime.strptime(datetime_str, '%Y%m%d_%H%M%S')
        except Exception:
            pass
        return None
    
    def _extract_session_id_from_file(self, file_path: Path) -> str:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’æŠ½å‡ºï¼ˆJSON/JSONLä¸¡å¯¾å¿œï¼‰"""
        try:
            import json
            
            if file_path.suffix == '.json':
                # æ–°å½¢å¼ï¼šçµ±åˆJSONãƒ•ã‚¡ã‚¤ãƒ«
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, dict) and 'session_id' in data:
                    return data['session_id']
            else:
                # æ—§å½¢å¼ï¼šJSONLãƒ•ã‚¡ã‚¤ãƒ«
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line_num, line in enumerate(f):
                        if line_num > 10:  # æœ€åˆã®10è¡Œã®ã¿ãƒã‚§ãƒƒã‚¯
                            break
                        try:
                            entry = json.loads(line.strip())
                            if 'session_id' in entry:
                                return entry['session_id']
                        except json.JSONDecodeError:
                            continue
            return "UNKNOWN"
        except Exception:
            return "UNKNOWN"
    
    def _count_log_entries(self, file_path: Path) -> int:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ãƒˆãƒªæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆJSON/JSONLä¸¡å¯¾å¿œï¼‰"""
        try:
            import json
            
            if file_path.suffix == '.json':
                # æ–°å½¢å¼ï¼šçµ±åˆJSONãƒ•ã‚¡ã‚¤ãƒ«
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, dict) and 'events' in data:
                    return len(data['events'])
                else:
                    return 1  # å˜ä¸€ã‚¨ãƒ³ãƒˆãƒª
            else:
                # æ—§å½¢å¼ï¼šJSONLãƒ•ã‚¡ã‚¤ãƒ«
                with open(file_path, 'r', encoding='utf-8') as f:
                    return sum(1 for line in f if line.strip())
        except Exception:
            return 0
    
    def _format_file_size(self, size_bytes: int) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
    
    def configure_logging(self, config: LogConfig) -> bool:
        """ãƒ­ã‚°è¨­å®šã®é©ç”¨"""
        try:
            import os
            
            # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®è¨­å®šèª­ã¿è¾¼ã¿
            logging_level = os.getenv('LOGGING_LEVEL', config.logging_level)
            max_file_size = int(os.getenv('MAX_LOG_FILE_SIZE', str(config.max_file_size_mb))) * 1024 * 1024
            max_log_files = int(os.getenv('MAX_LOG_FILES', str(config.max_log_files)))
            
            # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
            import logging as log_module
            level_map = {
                'DEBUG': log_module.DEBUG,
                'INFO': log_module.INFO,
                'WARNING': log_module.WARNING,
                'ERROR': log_module.ERROR
            }
            log_module.getLogger().setLevel(level_map.get(logging_level.upper(), log_module.INFO))
            
            # Google Sheetsè¨­å®š
            self._google_sheets_enabled = config.google_sheets_enabled
            if config.google_sheets_url:
                os.environ['GOOGLE_SHEETS_URL'] = config.google_sheets_url
            
            # ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’ä¿å­˜
            self._max_file_size = max_file_size
            self._max_log_files = max_log_files
            
            # SessionLoggerã«è¨­å®šã‚’é©ç”¨ï¼ˆæ—¢ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
            if self.session_logger:
                self.session_logger.max_log_files = max_log_files
            
            # è¨­å®šã®ä¿å­˜
            self._save_config_to_file(config)
            
            logger.info(f"ãƒ­ã‚°è¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ - ãƒ¬ãƒ™ãƒ«: {logging_level}, æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {max_file_size}B")
            return True
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°è¨­å®šã®é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _save_config_to_file(self, config: LogConfig) -> None:
        """è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            import config as app_config
            import json
            
            config_dir = app_config.ROOT_DIR / "data" / "config"
            config_dir.mkdir(parents=True, exist_ok=True)
            
            config_file = config_dir / "logging_config.json"
            
            config_data = {
                "logging_level": config.logging_level,
                "max_file_size_mb": config.max_file_size_mb,
                "max_log_files": config.max_log_files,
                "google_sheets_enabled": config.google_sheets_enabled,
                "google_sheets_url": config.google_sheets_url,
                "backup_enabled": config.backup_enabled,
                "auto_cleanup_enabled": config.auto_cleanup_enabled,
                "updated_at": datetime.now().isoformat()
            }
            
            with config_file.open('w', encoding='utf-8') as f:
                json.dump(config_data, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {config_file}")
            
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_config_from_file(self) -> LogConfig:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            import config as app_config
            import json
            
            config_file = app_config.ROOT_DIR / "data" / "config" / "logging_config.json"
            
            if not config_file.exists():
                logger.info("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
                return self._get_default_config()
            
            with config_file.open('r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            return LogConfig(
                logging_level=config_data.get('logging_level', 'INFO'),
                max_file_size_mb=config_data.get('max_file_size_mb', 10),
                max_log_files=config_data.get('max_log_files', 100),
                google_sheets_enabled=config_data.get('google_sheets_enabled', False),
                google_sheets_url=config_data.get('google_sheets_url', ''),
                backup_enabled=config_data.get('backup_enabled', True),
                auto_cleanup_enabled=config_data.get('auto_cleanup_enabled', True)
            )
            
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> LogConfig:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è¿”å´"""
        return LogConfig()
    
    def reset_to_default_config(self) -> bool:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã«ãƒªã‚»ãƒƒãƒˆ"""
        try:
            default_config = self._get_default_config()
            success = self.configure_logging(default_config)
            
            if success:
                logger.info("ãƒ­ã‚°è¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                print("âœ… ãƒ­ã‚°è¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
            else:
                logger.error("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ãƒªã‚»ãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                print("âŒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ãƒªã‚»ãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            return success
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒªã‚»ãƒƒãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def apply_log_rotation(self) -> bool:
        """ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        try:
            import config as app_config
            
            sessions_dir = app_config.ROOT_DIR / "data" / "sessions"
            if not sessions_dir.exists():
                return True
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            log_files = list(sessions_dir.glob("*.jsonl"))
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
            for log_file in log_files:
                if log_file.stat().st_size > self._max_file_size:
                    self._rotate_large_file(log_file)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã«ã‚ˆã‚‹å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            if len(log_files) > self._max_log_files:
                self._cleanup_old_files(log_files)
            
            logger.debug("ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return True
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _rotate_large_file(self, log_file: Path) -> None:
        """å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        try:
            import config as app_config
            import shutil
            
            backup_dir = app_config.ROOT_DIR / "data" / "backup"
            backup_dir.mkdir(parents=True, exist_ok=True)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_name = f"{log_file.stem}_backup_{timestamp}.jsonl"
            backup_path = backup_dir / backup_name
            
            shutil.move(str(log_file), str(backup_path))
            logger.info(f"å¤§ããªãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {log_file.name} -> {backup_name}")
            
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä¸­ã«ã‚¨ãƒ©ãƒ¼ ({log_file}): {e}")
    
    def _cleanup_old_files(self, log_files: List[Path]) -> None:
        """å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            import config as app_config
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°æ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤ã„ã‚‚ã®ã‹ã‚‰ï¼‰
            sorted_files = sorted(log_files, key=lambda f: f.stat().st_mtime)
            
            # åˆ¶é™ã‚’è¶…ãˆã‚‹åˆ†ã‚’å‰Šé™¤
            files_to_remove = len(sorted_files) - self._max_log_files
            if files_to_remove > 0:
                archived_dir = app_config.ROOT_DIR / "data" / "backup" / "archived"
                archived_dir.mkdir(parents=True, exist_ok=True)
                
                for file_to_archive in sorted_files[:files_to_remove]:
                    try:
                        import shutil
                        archived_path = archived_dir / file_to_archive.name
                        shutil.move(str(file_to_archive), str(archived_path))
                        logger.info(f"å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {file_to_archive.name}")
                    except Exception as e:
                        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ ({file_to_archive}): {e}")
                        
        except Exception as e:
            logger.error(f"å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def show_current_config(self) -> None:
        """ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º"""
        try:
            config = self.load_config_from_file()
            
            print("\nâš™ï¸  ç¾åœ¨ã®ãƒ­ã‚°è¨­å®š")
            print("=" * 50)
            print(f"ğŸ“Š ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«: {config.logging_level}")
            print(f"ğŸ“ æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {config.max_file_size_mb} MB")
            print(f"ğŸ“ æœ€å¤§ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {config.max_log_files}")
            print(f"ğŸ”— Google Sheetsé€£æº: {'æœ‰åŠ¹' if config.google_sheets_enabled else 'ç„¡åŠ¹'}")
            if config.google_sheets_url:
                print(f"ğŸ“‹ Google Sheets URL: {config.google_sheets_url}")
            print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {'æœ‰åŠ¹' if config.backup_enabled else 'ç„¡åŠ¹'}")
            print(f"ğŸ§¹ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {'æœ‰åŠ¹' if config.auto_cleanup_enabled else 'ç„¡åŠ¹'}")
            print()
            
        except Exception as e:
            logger.error(f"è¨­å®šè¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ è¨­å®šã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def validate_log_integrity(self, file_path: Optional[Path] = None) -> ValidationResult:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ•´åˆæ€§æ¤œè¨¼"""
        try:
            import config as app_config
            import json
            
            # æ¤œè¨¼å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®æ±ºå®š
            if file_path is None:
                file_path = self.get_latest_log_path()
            
            if file_path is None or not file_path.exists():
                return ValidationResult(
                    is_valid=False,
                    total_entries=0,
                    valid_entries=0,
                    corrupted_entries=[],
                    missing_fields=[],
                    error_details=["æ¤œè¨¼å¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"]
                )
            
            valid_entries = 0
            total_entries = 0
            corrupted_entries = []
            missing_fields = []
            error_details = []
            
            required_fields = {'timestamp', 'event_type'}
            
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    total_entries += 1
                    
                    try:
                        entry = json.loads(line)
                        
                        if not isinstance(entry, dict):
                            corrupted_entries.append(line_num)
                            error_details.append(f"è¡Œ{line_num}: JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                            continue
                        
                        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
                        entry_missing_fields = []
                        for field in required_fields:
                            if field not in entry:
                                entry_missing_fields.append(field)
                        
                        if entry_missing_fields:
                            missing_fields.extend([(line_num, field) for field in entry_missing_fields])
                            error_details.append(f"è¡Œ{line_num}: å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸è¶³: {', '.join(entry_missing_fields)}")
                        else:
                            valid_entries += 1
                            
                    except json.JSONDecodeError as e:
                        corrupted_entries.append(line_num)
                        error_details.append(f"è¡Œ{line_num}: JSONè§£æã‚¨ãƒ©ãƒ¼ - {str(e)}")
                    except Exception as e:
                        corrupted_entries.append(line_num)
                        error_details.append(f"è¡Œ{line_num}: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ - {str(e)}")
            
            is_valid = (len(corrupted_entries) == 0 and len(missing_fields) == 0 and valid_entries > 0)
            
            result = ValidationResult(
                is_valid=is_valid,
                total_entries=total_entries,
                valid_entries=valid_entries,
                corrupted_entries=corrupted_entries,
                missing_fields=[field for _, field in missing_fields],
                error_details=error_details
            )
            
            # æ¤œè¨¼çµæœã®ãƒ­ã‚°å‡ºåŠ›
            if is_valid:
                logger.info(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å®Œäº†: {file_path.name} - å…¨{total_entries}ã‚¨ãƒ³ãƒˆãƒªãŒæœ‰åŠ¹")
            else:
                logger.warning(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã§å•é¡Œæ¤œå‡º: {file_path.name} - æœ‰åŠ¹:{valid_entries}/{total_entries}")
            
            return result
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°æ•´åˆæ€§æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return ValidationResult(
                is_valid=False,
                total_entries=0,
                valid_entries=0,
                corrupted_entries=[],
                missing_fields=[],
                error_details=[f"æ¤œè¨¼å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"]
            )
    
    def repair_log_file(self, file_path: Path, backup: bool = True) -> bool:
        """ç ´æãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®å¾©"""
        try:
            import config as app_config
            import json
            import shutil
            
            if not file_path.exists():
                logger.error(f"ä¿®å¾©å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
                return False
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            if backup:
                backup_dir = app_config.ROOT_DIR / "data" / "backup"
                backup_dir.mkdir(parents=True, exist_ok=True)
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_path = backup_dir / f"{file_path.stem}_before_repair_{timestamp}.jsonl"
                shutil.copy2(str(file_path), str(backup_path))
                logger.info(f"ä¿®å¾©å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
            
            # æœ‰åŠ¹ãªã‚¨ãƒ³ãƒˆãƒªã®ã¿ã‚’æŠ½å‡º
            valid_entries = []
            repaired_entries = 0
            
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        entry = json.loads(line)
                        
                        if isinstance(entry, dict):
                            # åŸºæœ¬çš„ãªä¿®å¾©ã‚’è©¦è¡Œ
                            if 'timestamp' not in entry:
                                entry['timestamp'] = datetime.now().isoformat()
                                repaired_entries += 1
                            
                            if 'event_type' not in entry:
                                entry['event_type'] = 'unknown'
                                repaired_entries += 1
                            
                            valid_entries.append(entry)
                    except json.JSONDecodeError:
                        logger.warning(f"ä¿®å¾©ä¸å¯èƒ½ãªã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—: è¡Œ{line_num}")
                        continue
            
            # ä¿®å¾©ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãæˆ»ã—
            with open(file_path, 'w', encoding='utf-8') as f:
                for entry in valid_entries:
                    f.write(json.dumps(entry, ensure_ascii=False) + '\n')
            
            logger.info(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©å®Œäº†: {file_path} - {len(valid_entries)}ã‚¨ãƒ³ãƒˆãƒªä¿æŒ, {repaired_entries}ã‚¨ãƒ³ãƒˆãƒªä¿®å¾©")
            print(f"âœ… ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©å®Œäº†: {len(valid_entries)}ã‚¨ãƒ³ãƒˆãƒªä¿æŒ, {repaired_entries}ã‚¨ãƒ³ãƒˆãƒªä¿®å¾©")
            
            return True
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    
    def show_validation_report(self, result: ValidationResult) -> None:
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º"""
        try:
            print("\nğŸ” ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ•´åˆæ€§æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ")
            print("=" * 60)
            
            if result.is_valid:
                print("âœ… ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ­£å¸¸ã§ã™")
                print(f"ğŸ“Š ç·ã‚¨ãƒ³ãƒˆãƒªæ•°: {result.total_entries}")
                print(f"âœ… æœ‰åŠ¹ã‚¨ãƒ³ãƒˆãƒªæ•°: {result.valid_entries}")
            else:
                print("âš ï¸  ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                print(f"ğŸ“Š ç·ã‚¨ãƒ³ãƒˆãƒªæ•°: {result.total_entries}")
                print(f"âœ… æœ‰åŠ¹ã‚¨ãƒ³ãƒˆãƒªæ•°: {result.valid_entries}")
                print(f"âŒ ç ´æã‚¨ãƒ³ãƒˆãƒªæ•°: {len(result.corrupted_entries)}")
                print(f"âš ï¸  ä¸è¶³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {len(result.missing_fields)}")
                
                if result.corrupted_entries:
                    print(f"\nğŸ” ç ´æã‚¨ãƒ³ãƒˆãƒª (è¡Œç•ªå·): {', '.join(map(str, result.corrupted_entries))}")
                
                if result.missing_fields:
                    print(f"\nğŸ” ä¸è¶³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {', '.join(set(result.missing_fields))}")
                
                if result.error_details:
                    print("\nğŸ“ è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±:")
                    for detail in result.error_details[:5]:  # æœ€å¤§5ä»¶è¡¨ç¤º
                        print(f"   â€¢ {detail}")
                    if len(result.error_details) > 5:
                        print(f"   ... ä»– {len(result.error_details) - 5} ä»¶")
                
                # ä¿®å¾©æ¨å¥¨äº‹é …
                suggestions = result.get_recovery_suggestions()
                if suggestions:
                    print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
                    for suggestion in suggestions:
                        print(f"   â€¢ {suggestion}")
            
            print()
            
        except Exception as e:
            logger.error(f"æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def _create_simple_logger(self, log_dir: Path, session_id: str, student_id: str) -> None:
        """ç°¡æ˜“ç‰ˆSessionLoggerä»£æ›¿ã®ä½œæˆ"""
        
        class SimpleSessionLogger:
            def __init__(self, log_file_path: Path, session_id: str, student_id: str):
                self.log_file_path = log_file_path
                self.session_id = session_id
                self.student_id = student_id
                self.session_data = {
                    "session_id": session_id,
                    "student_id": student_id,
                    "start_time": None,
                    "end_time": None,
                    "stage_id": None,
                    "solve_code": None,  # solve()é–¢æ•°ã®ã‚³ãƒ¼ãƒ‰
                    "events": [],
                    "result": None  # action_countã¯ã“ã“ã«çµ±åˆ
                }
            
            def set_session_info(self, stage_id: str, solve_code: str = None):
                """ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¨­å®š"""
                self.session_data["stage_id"] = stage_id
                self.session_data["solve_code"] = solve_code
                if not self.session_data["start_time"]:
                    from datetime import datetime
                    self.session_data["start_time"] = datetime.now().isoformat()
            
            def log_event(self, event_type: str, data: dict = None) -> None:
                """ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã®è¨˜éŒ²ï¼ˆçµ±åˆå½¢å¼ï¼‰"""
                from datetime import datetime
                
                try:
                    # eventsã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯action_countã€total_execution_timeã€completed_successfullyã‚’å«ã‚ãªã„
                    if event_type == "session_complete" and data:
                        # session_completeã‚¤ãƒ™ãƒ³ãƒˆã§ã¯resultã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
                        event_data = {
                            "timestamp": datetime.now().isoformat(),
                            "event_type": event_type
                        }
                    else:
                        event_data = {
                            "timestamp": datetime.now().isoformat(),
                            "event_type": event_type,
                            **(data or {})
                        }
                    
                    self.session_data["events"].append(event_data)
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†æ™‚ã«çµ±åˆãƒ­ã‚°ã‚’æ›¸ãè¾¼ã¿
                    if event_type == "session_complete":
                        self.session_data["end_time"] = datetime.now().isoformat()
                        # resultã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«çµ±åˆï¼ˆtotal_execution_timeã‚’é™¤å»ï¼‰
                        result_data = {
                            "completed_successfully": data.get("completed_successfully", False),
                            "action_count": data.get("action_count", 0)
                        }
                        # ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆè¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆï¼‰ã‚’è¿½åŠ 
                        if self.session_data.get("solve_code"):
                            result_data["code_quality"] = self._calculate_code_metrics(self.session_data["solve_code"])
                        self.session_data["result"] = result_data
                        self._write_consolidated_log()
                        
                except Exception as e:
                    logger.error(f"ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
            
            def _calculate_code_metrics(self, solve_code: str) -> dict:
                """ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆè¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆç­‰ï¼‰ã‚’è¨ˆç®—"""
                try:
                    if not solve_code:
                        return {"line_count": 0, "comment_count": 0, "blank_count": 0}
                    
                    lines = solve_code.split('\n')
                    total_lines = len(lines)
                    comment_lines = 0
                    blank_lines = 0
                    
                    for line in lines:
                        stripped = line.strip()
                        if not stripped:
                            blank_lines += 1
                        elif stripped.startswith('#'):
                            comment_lines += 1
                    
                    code_lines = total_lines - comment_lines - blank_lines
                    
                    return {
                        "line_count": total_lines,
                        "code_lines": code_lines,
                        "comment_lines": comment_lines,
                        "blank_lines": blank_lines
                    }
                except Exception as e:
                    logger.error(f"ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                    return {"line_count": 0, "comment_count": 0, "blank_count": 0}
            
            def _write_consolidated_log(self):
                """çµ±åˆãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿"""
                import json
                
                try:
                    with open(self.log_file_path, 'w', encoding='utf-8') as f:
                        f.write(json.dumps(self.session_data, ensure_ascii=False, indent=2))
                except Exception as e:
                    logger.error(f"çµ±åˆãƒ­ã‚°æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.session_logger = SimpleSessionLogger(self.log_file_path, session_id, student_id)
    
    def get_attempt_count_for_stage(self, student_id: str, stage_id: str) -> int:
        """æŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ†ãƒ¼ã‚¸ã®æŒ‘æˆ¦å›æ•°ã‚’å–å¾—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒ™ãƒ¼ã‚¹ï¼‰"""
        try:
            import config
            base_sessions_dir = config.ROOT_DIR / "data" / "sessions"
            stage_dir = base_sessions_dir / stage_id  # data/sessions/stage01/
            
            if not stage_dir.exists():
                return 0
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            json_files = list(stage_dir.glob(f"*_{student_id}.json"))
            return len(json_files)
            
        except Exception as e:
            logger.error(f"æŒ‘æˆ¦å›æ•°å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
    
    def notify_log_location(self, file_path: Path) -> None:
        """ç”Ÿæˆã•ã‚ŒãŸãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®é€šçŸ¥"""
        if file_path:
            print(f"ğŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
            print(f"ğŸ“‚ ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {file_path.parent}")
        else:
            print("âš ï¸ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    
    def provide_log_access_method(self) -> str:
        """ãƒ­ã‚°å‚ç…§æ–¹æ³•ã®æä¾›"""
        if not self.log_file_path:
            return "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
        
        access_methods = f"""
ğŸ“‹ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§æ–¹æ³•:

1. ãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥ç¢ºèª:
   {self.log_file_path}

2. ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³è¡¨ç¤º:
   cat "{self.log_file_path}"
   
3. JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¡¨ç¤º:
   python -m json.tool "{self.log_file_path}"
   
4. æœ€æ–°10è¡Œè¡¨ç¤º:
   tail -10 "{self.log_file_path}"
"""
        
        print(access_methods)
        return str(self.log_file_path)
    
    def log_session_start(self, additional_data: Optional[Dict[str, Any]] = None) -> None:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã®ãƒ­ã‚°è¨˜éŒ²"""
        try:
            if self.session_logger:
                session_data = {
                    "event_type": "session_start",
                    "timestamp": datetime.now().isoformat(),
                    "execution_mode": "gui_enhanced_v1.1"
                }
                if additional_data:
                    session_data.update(additional_data)
                    
                self.session_logger.log_event("session_start", session_data)
                logger.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ãƒ­ã‚°è¨˜éŒ²å®Œäº†")
                
        except Exception as e:
            logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ãƒ­ã‚°è¨˜éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def log_session_complete(self, execution_summary: Dict[str, Any]) -> None:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†æ™‚ã®ãƒ­ã‚°è¨˜éŒ²"""
        try:
            if self.session_logger:
                completion_data = {
                    "event_type": "session_complete",
                    "timestamp": datetime.now().isoformat(),
                    **execution_summary
                }
                
                self.session_logger.log_event("session_complete", completion_data)
                logger.info("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†ãƒ­ã‚°è¨˜éŒ²å®Œäº†")
                
                # æœ€çµ‚çš„ãªãƒ­ã‚°å‚ç…§æ–¹æ³•ã‚’è¡¨ç¤º
                print("\nğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸ")
                self.provide_log_access_method()
                
        except Exception as e:
            logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†ãƒ­ã‚°è¨˜éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def is_logging_enabled(self) -> bool:
        """ãƒ­ã‚°æ©Ÿèƒ½ã®æœ‰åŠ¹æ€§ç¢ºèª"""
        return self.enabled
    
    def get_log_file_path(self) -> Optional[Path]:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å–å¾—"""
        return self.log_file_path
    
    def get_session_logger(self) -> Optional[SessionLogger]:
        """SessionLoggerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å–å¾—"""
        return self.session_logger
    
    def flush_logs(self) -> None:
        """ãƒ­ã‚°ã®ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆå³åº§ã«ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ï¼‰"""
        try:
            if self.session_logger:
                # SessionLoggerã«flushãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚Œã°ä½¿ç”¨
                if hasattr(self.session_logger, 'flush'):
                    self.session_logger.flush()
                logger.debug("ãƒ­ã‚°ãƒ•ãƒ©ãƒƒã‚·ãƒ¥å®Œäº†")
                
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def cleanup(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if self.session_logger:
                # SessionLoggerã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if hasattr(self.session_logger, 'close'):
                    self.session_logger.close()
                    
            self.enabled = False
            self.session_logger = None
            self.log_file_path = None
            
            logger.debug("SessionLogManager ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            logger.error(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")